{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The knowledge created on this dataset will be exported as transformers and saved on **libs/transformers.py** so it can be reusable in sklearn pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pipelines as andre_pipelines\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10670/809342345.py:1: DtypeWarning: Columns (1,11,12,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../beijing.csv', encoding=\"gbk\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../beijing.csv', encoding=\"gbk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting assured columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['url'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutating or one-hot-encoding columns since string stuff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tradeTime date column to timestamp\n",
    "df['tradeTime'] = pd.to_datetime(df['tradeTime']).astype(int)/ 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming id column to numeric\n",
    "df['id'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livingRoom\n",
       "0            11\n",
       "1         42138\n",
       "2         77256\n",
       "3         31567\n",
       "4          3349\n",
       "5           537\n",
       "6           126\n",
       "7            22\n",
       "8             3\n",
       "9             2\n",
       "#NAME?       32\n",
       "0            17\n",
       "1         40248\n",
       "2         83333\n",
       "3         36044\n",
       "4          3472\n",
       "5           570\n",
       "6           102\n",
       "7            15\n",
       "8             4\n",
       "9             3\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This column unfortunately has the same labels as string and int object.\n",
    "# There is a label '#NAME?' which is not clear for what use it is. Since only 32 of them, we can fill it with the median if the column (Since discrete values)\n",
    "df.groupby('livingRoom')['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "livingRoom\n",
       "0.0        28\n",
       "1.0     82386\n",
       "2.0    160621\n",
       "3.0     67611\n",
       "4.0      6821\n",
       "5.0      1107\n",
       "6.0       228\n",
       "7.0        37\n",
       "8.0         7\n",
       "9.0         5\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_livingRoom(x):\n",
    "    if x == '#NAME?':\n",
    "        return np.nan\n",
    "    else: return int(x)\n",
    "df['livingRoom'] = df['livingRoom'].apply(fix_livingRoom)\n",
    "df['livingRoom'] = df['livingRoom'].fillna(int(df['livingRoom'].median()))\n",
    "df.groupby('livingRoom')['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drawingRoom\n",
       "0        11300\n",
       "1       109783\n",
       "2        33418\n",
       "3          474\n",
       "4           31\n",
       "5            5\n",
       "0         8386\n",
       "1       115876\n",
       "2        39084\n",
       "3          444\n",
       "4           16\n",
       "5            2\n",
       "中 14         2\n",
       "中 15         1\n",
       "中 16         3\n",
       "中 22         1\n",
       "中 24         1\n",
       "中 6          6\n",
       "低 15         1\n",
       "低 16         1\n",
       "低 6          7\n",
       "底 11         1\n",
       "底 20         1\n",
       "底 28         1\n",
       "顶 6          2\n",
       "高 12         1\n",
       "高 14         2\n",
       "高 6          1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('drawingRoom')['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318851 entries, 0 to 318850\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   318851 non-null  int64  \n",
      " 1   Lng                  318851 non-null  float64\n",
      " 2   Lat                  318851 non-null  float64\n",
      " 3   Cid                  318851 non-null  int64  \n",
      " 4   tradeTime            318851 non-null  float64\n",
      " 5   DOM                  160874 non-null  float64\n",
      " 6   followers            318851 non-null  int64  \n",
      " 7   totalPrice           318851 non-null  float64\n",
      " 8   price                318851 non-null  int64  \n",
      " 9   square               318851 non-null  float64\n",
      " 10  livingRoom           318851 non-null  float64\n",
      " 11  drawingRoom          318851 non-null  object \n",
      " 12  kitchen              318851 non-null  int64  \n",
      " 13  bathRoom             318851 non-null  object \n",
      " 14  floor                318851 non-null  object \n",
      " 15  buildingType         316830 non-null  float64\n",
      " 16  constructionTime     318851 non-null  object \n",
      " 17  renovationCondition  318851 non-null  int64  \n",
      " 18  buildingStructure    318851 non-null  int64  \n",
      " 19  ladderRatio          318851 non-null  float64\n",
      " 20  elevator             318819 non-null  float64\n",
      " 21  fiveYearsProperty    318819 non-null  float64\n",
      " 22  subway               318819 non-null  float64\n",
      " 23  district             318851 non-null  int64  \n",
      " 24  communityAverage     318388 non-null  float64\n",
      "dtypes: float64(13), int64(8), object(4)\n",
      "memory usage: 60.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOM                  True\n",
       "buildingType         True\n",
       "elevator             True\n",
       "fiveYearsProperty    True\n",
       "subway               True\n",
       "communityAverage     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=df.isnull().mean()>0 \n",
    "missing[missing == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318851 entries, 0 to 318850\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   DOM                160874 non-null  float64\n",
      " 1   buildingType       316830 non-null  float64\n",
      " 2   elevator           318819 non-null  float64\n",
      " 3   fiveYearsProperty  318819 non-null  float64\n",
      " 4   subway             318819 non-null  float64\n",
      " 5   communityAverage   318388 non-null  float64\n",
      " 6   totalPrice         318851 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 17.0 MB\n"
     ]
    }
   ],
   "source": [
    "# dependant variables: DOM, buildingType, elevator, fiveYearsProperty, subway, communityAverage\n",
    "# target variable: totalPrice\n",
    "cols_to_use = ['DOM', 'buildingType', 'elevator', 'fiveYearsProperty', 'subway', 'communityAverage', 'totalPrice']\n",
    "data_simp = df[cols_to_use]\n",
    "data_simp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOM                  0.495457\n",
       "buildingType         0.006338\n",
       "elevator             0.000100\n",
       "fiveYearsProperty    0.000100\n",
       "subway               0.000100\n",
       "communityAverage     0.001452\n",
       "totalPrice           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_simp.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can i accept 0 as a value for these missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the six variables, only one have a missinge percentage greater than 5%, the DOM variable\n",
    "- The DOM variable means **Active days on market** and it has a missing percentage of almost 50% but the .isnull function from pandas recognizes the value zero as null but zero may be an important label. It could mean that the property on sale could be zero active days on market. We need to find out if it is completely random or not. If it is not random, than probably some zeros are treated the same as null and as zero active days on market.\n",
    "\n",
    "Hypothesen:\n",
    " - H(null): The data was produced in a random manner.  \n",
    " - H(alternative): The data was not produced in a random manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  28.822339221999826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-313.444522743472, 0.0)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "\n",
    "dom_values = df['DOM'].to_list()\n",
    "print(\"mean: \", df['DOM'].mean())\n",
    "\n",
    "# Perform Runs test\n",
    "runstest_1samp(dom_values, cutoff=df['DOM'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z_stat: -313.44; p-value: 0%  \n",
    "Since the p-value is smaller than 5%, we need to accept the null hypothesis. \n",
    "This means, that the zero values of DOM are randomly generated. Let's analyse further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for near-zero variance and eliminate columns with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10670/2452669276.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.var()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                     8.472190e+09\n",
       "Lng                    1.255617e-02\n",
       "Lat                    8.460789e-03\n",
       "Cid                    5.585881e+24\n",
       "tradeTime              2.670821e+15\n",
       "DOM                    2.523791e+03\n",
       "followers              1.170268e+03\n",
       "totalPrice             5.325977e+04\n",
       "price                  4.712817e+08\n",
       "square                 1.386420e+03\n",
       "livingRoom             6.033926e-01\n",
       "kitchen                1.201411e-02\n",
       "buildingType           1.612538e+00\n",
       "renovationCondition    1.720658e+00\n",
       "buildingStructure      3.616666e+00\n",
       "ladderRatio            6.284300e+08\n",
       "elevator               2.440633e-01\n",
       "fiveYearsProperty      2.288009e-01\n",
       "subway                 2.397771e-01\n",
       "district               7.910809e+00\n",
       "communityAverage       4.985939e+08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get variance of each column\n",
    "df.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '中 14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10670/3203014777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVarianceThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.05 is 5% of the variance of the column^\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fit and transform the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_variance_threshold.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '中 14'"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.05) # 0.05 is 5% of the variance of the column^\n",
    "df_filtered = selector.fit_transform(df) # fit and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VarianceThreshold' object has no attribute 'var'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10670/598807585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'VarianceThreshold' object has no attribute 'var'"
     ]
    }
   ],
   "source": [
    "df_filtered"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
