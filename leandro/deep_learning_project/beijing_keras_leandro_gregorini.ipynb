{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d8ade0",
   "metadata": {},
   "source": [
    "# Beijing Housing - Leandro Gregorini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a79bbe",
   "metadata": {},
   "source": [
    "## Inhaltsverzeichnis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b256f022",
   "metadata": {},
   "source": [
    "* [Imports](#Imports)\n",
    "* [Modell](#Modell)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6073a232",
   "metadata": {},
   "source": [
    "## Imports <a class=\"anchor\" id=\"Imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa11181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# deep learning libraries\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualisierung\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras_visualizer import visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5db017",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea5d3fa1",
   "metadata": {},
   "source": [
    "## Deep Learning Modell für den Beijing Datensatz <a class=\"anchor\" id=\"Modell\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9d68a",
   "metadata": {},
   "source": [
    "### Analyse der Parameter und Begründungen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "595fef20",
   "metadata": {},
   "source": [
    "- **Hidden Layers**\n",
    "    - **Beschreibung**: <br>\n",
    "Die mittlere Schicht bzw. Schichten eines Deep Learning Netzwerks werden als \"Hidden Layers\" bezeichnet.\n",
    "Die Neuronen dieser Schichten sind weder \"Inputs\" noch \"Outputs\".\n",
    "Die notwendige Anzahl von Ebenen kann beliebig festgelegt werden und es ist oft schwer die \"beste\" Anzahl zu finden (oft werden jedoch 2 eingesetzt).\n",
    "<br><br>\n",
    "<br> Die gängigsten Fälle die eintreten:\n",
    "<br>- 0 Hidden Layers: Nur in der Lage linear trennbare Funktionen oder Entscheidungen darzustellen\n",
    "<br>- 1 Hidden Layer: Kann jede Funktion annähern, die eine kontinuierliche Abbildung von einem endlichen Raum zu einem anderen enthält\n",
    "<br>- 2 Hidden Layers: Kann mit rationalen Aktivierungsfunktionen eine beliebige Entscheidungsgrenze mit beliebiger Genauigkeit darstellen\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Nodes**\n",
    "    - **Beschreibung** <br>\n",
    "Mit der Anzahl Nodes legt man fest, wie viele Neuronen in den verschiedenen Schichten eingesetzt werden. Die Input-Nodes ergeben sich aus der Problemstellung, im Fall vom MNIST Datensatz sind es 784 Neuronen (28x28), diese Zahl wird durch die Anzahl Pixel der Bilder vorgegeben. Die Output-Nodes werden ebenfalls auf die Problemstellung angepasst, im Fall vom MNIST Datensatz sind es 10 Neuronen, da man eine Zahl zwischen 0 und 10 vorhersagen möchte.\n",
    "<br><br>\n",
    "<br> Die Anzahl Hidden-Nodes können mit folgenden Faustregeln festgelegt werden:\n",
    "<br>- Die Anzahl der Hidden-Nodes sollte zwischen der Anzahl Nodes im Input- und Output Layer liegen\n",
    "<br>- Die Anzahl der Hidden-Nodes sollte 2/3 der Anzahl Nodes im Input Layer plus der Anzahl Nodes im Output Layer sein\n",
    "<br>- Die Anzahl der Hidden-Nodes sollte weniger als die doppelte Anzahl an Nodes im Input Layer sein.\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Batches**\n",
    "    - **Beschreibung** <br>\n",
    "Die batch size definiert die Anzahl an Trainingsdaten, die durch das Netzwerk in einer \"Iteration\" weitergegeben werden.\n",
    "<br><br>\n",
    "Vorteile für das Verwenden einer batch size < Anzahl aller Trainingsdaten:\n",
    "<br>- Es erfordert weniger Speicher\n",
    "<br>- Typischerweise trainieren Netzwerke mit Mini-Batches schneller.\n",
    "<br>\n",
    "Nachteile:\n",
    "<br>- Umso kleiner der Batch ist, desto ungenauer wird die Schätzung des Gradienten sein. \n",
    "<br><br> Folgende Batch sizes können je nach Hardware eingesetzt werden:\n",
    "<br>- 1, 2, 4, 8, 16 - eher lange Trainingszeit\n",
    "<br>- 32 oder 64 - Beim Rechnen mit CPU\n",
    "<br>- 128 oder 256 - Beim Rechnen mit GPU\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Epochs**\n",
    "    - **Beschreibung** <br>\n",
    "Ein kompletter Durchlauf aller Input-Daten wird als Epoche bezeichnet. Dabei können die Input-Daten je nach Größe des Datensatzes auch in gleich große Gruppen (Batches) eingeteilt werden und das Training kann jeweils pro Batch durchgeführt werden.\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Activation function**\n",
    "    - **Beschreibung** <br>\n",
    "Die Wahl der Aktivierungsfunktion im Hidden Layer bestimmt, wie gut das Modell den Trainingsdatensatz erlernt.\n",
    "<br><br>\n",
    "Folgende Funktionen gibt es für die Hidden Layers:\n",
    "<br>- Rectified Linear Activation (ReLU)\n",
    "<br>- Logistic (Sigmoid)\n",
    "<br>- Hyperbolic Tangent (Tanh)\n",
    "<br><br>\n",
    "Folgende Funktionen gibt es für den Output Layer:\n",
    "<br>- Regression: linear\n",
    "<br>- Klassifikation: softmax oder sigmoid (sollte nur verwendet werden, wenn mehrere Outputs als \"richtige\" Antworten gelten sollen)\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Regularization**\n",
    "    - **Beschreibung** <br>\n",
    "Mit Regularisierung möchte man Overfitting in neuronalen Netzen reduzieren und somit die Genauigkeit eines Deep Learning Modells bei Anwendung auf komplett neue Daten verbessern.\n",
    "<br><br>\n",
    "Es gibt verschiedene Arten der Regularisierung:\n",
    "<br>- L1-Regularisierung: Kann als eine Art Neuronenselektion betrachtet werden, da sie die Gewichte einiger versteckter Neuronen auf Null bringt.\n",
    "<br>- L2-Regularisierung: Die Werte der Gewichte werden gegen Null gebracht, was zu einem einfacheren Modell führt.\n",
    "<br>- Dropout: Die Idee der Dropout-Regularisierung besteht darin, einige Knoten nach dem Zufallsprinzip zu entfernen. Wie bei der L2-Regularisierung vereinfacht sich das Modell und die Komplexität wird somit reduziert.\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n",
    "\n",
    "<br><br>\n",
    "- **Optimizer**\n",
    "    - **Beschreibung** <br>\n",
    "Optimizer sind Algorithmen oder Methoden, die zur Minimierung einer Fehlerfunktion (Verlustfunktion) oder zur Maximierung der Effizienz eingesetzt werden (Oft \"Gradient descent\"). Optimizer sind mathematische Funktionen, die von den Parametern des Modells abhängen, d.h. von den weights und biases.\n",
    "<br> Im Keras Paket gibt es viele Optimizer, welche verwendet werden können, diese sind in der <a href=\"https://keras.io/api/optimizers/\">Dokumentation</a> genauer beschrieben.\n",
    "<br><br>\n",
    "Grobe Übersicht:\n",
    "<br>- Gradient Descent: Batch gradient descent, stochastic gradient descent, mini-batch gradient descent\n",
    "<br>- Adaptive: Adagrad, Adadelta, RMSprop, Adam\n",
    "    <br><br>\n",
    "    - **Begründung der Auswahl** <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0ba65",
   "metadata": {},
   "source": [
    "### Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e959ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed Daten laden\n",
    "trainDF = pd.read_csv('../../app/data/02_train.csv', sep=';')\n",
    "testDF = pd.read_csv('../../app/data/02_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed3f9406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lng</th>\n",
       "      <th>Lat</th>\n",
       "      <th>square</th>\n",
       "      <th>livingRoom</th>\n",
       "      <th>drawingRoom</th>\n",
       "      <th>kitchen</th>\n",
       "      <th>bathRoom</th>\n",
       "      <th>floor</th>\n",
       "      <th>buildingType</th>\n",
       "      <th>renovationCondition</th>\n",
       "      <th>...</th>\n",
       "      <th>placeRank</th>\n",
       "      <th>town</th>\n",
       "      <th>districtPopulation</th>\n",
       "      <th>districtArea</th>\n",
       "      <th>tradeYear</th>\n",
       "      <th>tradeMonth</th>\n",
       "      <th>tradeDay</th>\n",
       "      <th>floorType</th>\n",
       "      <th>constructionTimePeriod</th>\n",
       "      <th>totalPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116.346109</td>\n",
       "      <td>39.756539</td>\n",
       "      <td>73.61</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>118742</td>\n",
       "      <td>53150</td>\n",
       "      <td>...</td>\n",
       "      <td>133606</td>\n",
       "      <td>219943</td>\n",
       "      <td>1993591.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>82499</td>\n",
       "      <td>136686</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.423426</td>\n",
       "      <td>39.964365</td>\n",
       "      <td>58.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>118742</td>\n",
       "      <td>81641</td>\n",
       "      <td>...</td>\n",
       "      <td>133606</td>\n",
       "      <td>219943</td>\n",
       "      <td>3452460.0</td>\n",
       "      <td>470.8</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>82499</td>\n",
       "      <td>136686</td>\n",
       "      <td>317.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.513137</td>\n",
       "      <td>39.978272</td>\n",
       "      <td>94.47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>118742</td>\n",
       "      <td>81641</td>\n",
       "      <td>...</td>\n",
       "      <td>133606</td>\n",
       "      <td>219943</td>\n",
       "      <td>3452460.0</td>\n",
       "      <td>470.8</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>18058</td>\n",
       "      <td>136686</td>\n",
       "      <td>301.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.473376</td>\n",
       "      <td>39.875385</td>\n",
       "      <td>131.63</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>58087</td>\n",
       "      <td>53150</td>\n",
       "      <td>...</td>\n",
       "      <td>81988</td>\n",
       "      <td>219943</td>\n",
       "      <td>3452460.0</td>\n",
       "      <td>470.8</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>25725</td>\n",
       "      <td>136686</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.471931</td>\n",
       "      <td>40.008739</td>\n",
       "      <td>103.14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>58087</td>\n",
       "      <td>53150</td>\n",
       "      <td>...</td>\n",
       "      <td>81988</td>\n",
       "      <td>219943</td>\n",
       "      <td>3452460.0</td>\n",
       "      <td>470.8</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>82499</td>\n",
       "      <td>136686</td>\n",
       "      <td>670.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lng        Lat  square  livingRoom  drawingRoom  kitchen  bathRoom  \\\n",
       "0  116.346109  39.756539   73.61           3            1        1         1   \n",
       "1  116.423426  39.964365   58.29           2            1        1         1   \n",
       "2  116.513137  39.978272   94.47           2            1        1         1   \n",
       "3  116.473376  39.875385  131.63           3            1        1         2   \n",
       "4  116.471931  40.008739  103.14           3            2        1         1   \n",
       "\n",
       "   floor  buildingType  renovationCondition  ...  placeRank    town  \\\n",
       "0      6        118742                53150  ...     133606  219943   \n",
       "1      5        118742                81641  ...     133606  219943   \n",
       "2      9        118742                81641  ...     133606  219943   \n",
       "3     22         58087                53150  ...      81988  219943   \n",
       "4     18         58087                53150  ...      81988  219943   \n",
       "\n",
       "   districtPopulation  districtArea  tradeYear  tradeMonth  tradeDay  \\\n",
       "0           1993591.0        1012.0       2017           8         6   \n",
       "1           3452460.0         470.8       2013           5        14   \n",
       "2           3452460.0         470.8       2012          12        29   \n",
       "3           3452460.0         470.8       2015           4         9   \n",
       "4           3452460.0         470.8       2017          12         7   \n",
       "\n",
       "   floorType  constructionTimePeriod  totalPrice  \n",
       "0      82499                  136686       347.0  \n",
       "1      82499                  136686       317.0  \n",
       "2      18058                  136686       301.5  \n",
       "3      25725                  136686       405.0  \n",
       "4      82499                  136686       670.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b23dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = trainDF.drop(['totalPrice'], axis=1)\n",
    "y_train = trainDF['totalPrice']\n",
    "x_test = testDF.drop(['totalPrice'], axis=1)\n",
    "y_test = testDF['totalPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71f09262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape x_train : (219943, 26)\n",
      "Shape x_test : (94262, 26)\n",
      "Shape y_train : (219943,)\n",
      "Shape y_test : (94262,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape x_train : {x_train.shape}')\n",
    "print(f'Shape x_test : {x_test.shape}')\n",
    "print(f'Shape y_train : {y_train.shape}')\n",
    "print(f'Shape y_test : {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974e500",
   "metadata": {},
   "source": [
    "### Optimizer vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e309a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für Optimizer je nach Auswahl in der Konfiguration\n",
    "def get_optimizer(optimizer_name, learning_rate):\n",
    "    #'sgd','rmsprop','adam','adagrad'\n",
    "    optimizer=None\n",
    "\n",
    "    if optimizer_name == 'adagrad':\n",
    "        optimizer = keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "\n",
    "    elif 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    elif 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    else:\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058c592",
   "metadata": {},
   "source": [
    "### Modell initialisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0363980b",
   "metadata": {},
   "source": [
    "> Code-Snippets aus Kurs CDS-108 (siehe Referenzen unten im Dokument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f77583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguration des Models (gespeichert in einem dict)\n",
    "model_config = {\n",
    "            \"INPUT_SHAPE\" : (x_train.shape[1],),                # Form des Inputs (Für Boston Housing: Anzahl features)\n",
    "            \"HIDDEN_NODES\" : [10,10],                           # Anzahl Neuronen im Hidde Layer (Es werden 2 Hidden-Layers eingesetzt) wird auf 10 festgelegt -> 2/3 der Anzahl Input Nodes + Anzahl Output Nodes\n",
    "            \"HIDDEN_ACTIVATION\" : \"relu\",                       # Aktivierungsfunktion im Hidden Layer\n",
    "            \"OUTPUT_NODES\" : 1,                                 # Output nodes des Output Layers\n",
    "            \"OUTPUT_ACTIVATION\" : None,\n",
    "            \"WEIGHTS_INITIALIZER\" : \"random_normal\",            # Initialisierung der Gewichte\n",
    "            \"BIAS_INITIALIZER\" : \"zeros\",                       # Initialisierung des Bias\n",
    "            \"NORMALIZATION\" : \"none\",                           # Normalisierung\n",
    "            \"OPTIMIZER\" : \"rmsprop\",                            # Root Mean Square Propagation\n",
    "            \"LEARNING_RATE\" : 0.01,                             # Lernrate für \"Gradient descent\" (0.01 oder 0.1 meist standard)\n",
    "            \"REGULARIZER\" : None,                               # Regularisierung (L1, L2)\n",
    "            \"DROPOUT_RATE\" : 0.15,                              # Regularisierung (Dropout)\n",
    "            \"EPOCHS\" : 101,                                     # Anzahl der Epochen, welche trainiert werden sollen\n",
    "            \"BATCH_SIZE\" : 4,                                   # Anzahl Daten pro batch\n",
    "            \"VALIDATION_SPLIT\" : 0.2,                           # Grösse des Validierungs-Datensatzes\n",
    "            \"VERBOSE\" : 1,                                      # Bestimmt die Ausgabe von Infos beim Tranieren des Modells (verbose=0: silent, verbose=1: animierte Anzeige, verbose=2: Zeigt nur die Anzahl Epochen an, welche abgearbeitet wurden)\n",
    "            \"LOSS_FUNCTION\" : \"mse\",                            # Kostenfunktion (MSE für Regression)\n",
    "            \"METRICS\" : [\"RootMeanSquaredError\"]                # Optimierungs-Metrik\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model_name, model_config):\n",
    "    model=tf.keras.models.Sequential(name=model_name)  # Keras Layers in sequentieller Ordnung aufbauen\n",
    "\n",
    "    for layer in range(len(model_config[\"HIDDEN_NODES\"])):  # Anzahl Hidden Layers\n",
    "        if layer == 0:\n",
    "            # Erster Hidden Layer und Input Layer hinzufügen\n",
    "            model.add(\n",
    "                    tf.keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
    "                    input_shape=model_config[\"INPUT_SHAPE\"],\n",
    "                    name=\"Dense-Layer-\" + str(layer),\n",
    "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
    "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
    "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
    "                    activation=model_config[\"HIDDEN_ACTIVATION\"]))\n",
    "        else:\n",
    "            # Weitere Hidden Layers hinzufügen\n",
    "            model.add(\n",
    "                    tf.keras.layers.Dense(model_config[\"HIDDEN_NODES\"][layer],\n",
    "                    name=\"Dense-Layer-\" + str(layer),\n",
    "                    kernel_initializer = model_config[\"WEIGHTS_INITIALIZER\"],\n",
    "                    bias_initializer = model_config[\"BIAS_INITIALIZER\"],\n",
    "                    kernel_regularizer=model_config[\"REGULARIZER\"],\n",
    "                    activation=model_config[\"HIDDEN_ACTIVATION\"]))\n",
    "            \n",
    "            # Weitere Layers hinzufügen\n",
    "            if model_config[\"NORMALIZATION\"] == \"batch\":\n",
    "                model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "            if model_config[\"DROPOUT_RATE\"] > 0.0:\n",
    "                model.add(tf.keras.layers.Dropout(model_config[\"DROPOUT_RATE\"]))\n",
    "                \n",
    "    model.add(tf.keras.layers.Dense(model_config[\"OUTPUT_NODES\"],\n",
    "                    name=\"Output-Layer\",\n",
    "                    activation=model_config[\"OUTPUT_ACTIVATION\"]))\n",
    "\n",
    "    optimizer = get_optimizer( model_config[\"OPTIMIZER\"],\n",
    "                              model_config[\"LEARNING_RATE\"])\n",
    "\n",
    "    model.compile(loss=model_config[\"LOSS_FUNCTION\"],\n",
    "                  optimizer=optimizer,\n",
    "                   metrics=model_config[\"METRICS\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model(model_name = \"BEIJING-MODEL\", model_config = model_config)  # load/prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ee646",
   "metadata": {},
   "source": [
    "### Modell visualisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63907791",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer(model, file_name=\"BEIJING-MODEL\", file_format='png')  # visualizer from keras_visualizer package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e2d5a1a",
   "metadata": {},
   "source": [
    "<img src=\"BEIJING-MODEL.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file=\"BEIJING-MODEL_KERAS.png\", show_shapes=True, show_layer_names=True)  # visualizer integrated in keras package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218fdad4",
   "metadata": {},
   "source": [
    "### Modell erstellen und trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0cd9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebca25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, x_train, y_train, stratify):\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "                            x_train, y_train,\n",
    "                            stratify=stratify,\n",
    "                            test_size=model_config[\"VALIDATION_SPLIT\"])\n",
    "\n",
    "    history=model.fit(X_train,\n",
    "              Y_train,\n",
    "              batch_size=model_config[\"BATCH_SIZE\"],\n",
    "              epochs=model_config[\"EPOCHS\"],\n",
    "              verbose=model_config[\"VERBOSE\"],\n",
    "              validation_data= (X_val, Y_val))\n",
    "    return history, model, X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model, X_train, Y_train, X_val, Y_val = run_model(model=model, x_train=x_train, y_train=y_train, stratify=None)  # save trained model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc348840",
   "metadata": {},
   "source": [
    "### Modell evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_regression(model, x_data, y_data, verbose=2):\n",
    "    score=model.evaluate(x_data, y_data, verbose=verbose)\n",
    "    mse_score = score[0]\n",
    "    mae_score = score[1]\n",
    "    return mse_score, mae_score\n",
    "\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"Scores\")\n",
    "print(\"------------------------------------------------------------------------------\\n\")\n",
    "print(\"Train data\")\n",
    "x_train_mse_score, x_train_mae_score = get_score_regression(model=model, x_data=X_train, y_data=Y_train)  # store scores\n",
    "print(\"x_train MSE:\", x_train_mse_score)\n",
    "print(\"x_train MAE:\", x_train_mae_score)\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"Test data\")\n",
    "x_test_mse_score, x_test_mae_score = get_score_regression(model=model, x_data=x_test, y_data=y_test)  # store scores\n",
    "print(\"x_test MSE:\", x_test_mse_score)\n",
    "print(\"x_test MAE:\", x_test_mae_score)\n",
    "print(\"\\n------------------------------------------------------------------------------\")\n",
    "print(\"Validation data\")\n",
    "x_val_mse_score, x_val_mae_score = get_score_regression(model=model, x_data=X_val, y_data=Y_val)  # store scores\n",
    "print(\"x_val MSE:\", x_val_mse_score)\n",
    "print(\"x_val MAE:\", x_val_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measures_regression(model_name, history=history, title=\"Measures\", accuracy_measures_to_plot=[\"train_loss\", \"train_root_mean_squared_error\", \"val_loss\", \"val_root_mean_squared_error\"]):\n",
    "    accuracy_measures={}\n",
    "    accuracy_measures[\"train_loss\"] = history.history[\"loss\"]\n",
    "    accuracy_measures[\"train_root_mean_squared_error\"] = history.history[\"root_mean_squared_error\"]\n",
    "    accuracy_measures[\"val_loss\"] = history.history[\"val_loss\"]\n",
    "    accuracy_measures[\"val_root_mean_squared_error\"] = history.history[\"val_root_mean_squared_error\"]\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for measure in accuracy_measures.keys():\n",
    "        if measure in accuracy_measures_to_plot:\n",
    "            plt.plot(accuracy_measures[measure], label=measure, linewidth=3)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"RMSE/Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f147c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measures_regression(model_name=\"MNIST-MODEL\", history=history, title=\"RMSE\",accuracy_measures_to_plot=[\"train_root_mean_squared_error\", \"val_root_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da668e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_measures_regression(model_name=\"BOSTON-HOUSING-MODEL\", history=history, title=\"Loss\", accuracy_measures_to_plot=[\"train_loss\", \"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73741e7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aa52d0",
   "metadata": {},
   "source": [
    "## Referenzen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca18c3",
   "metadata": {},
   "source": [
    "- Code Snippets/Informationen aus Kurs CDS-108: https://moodle.fhgr.ch/course/view.php?id=14551\n",
    "- Tensorflow/Keras Doku: https://www.tensorflow.org/datasets/keras_example\n",
    "- Hidden Layers: https://medium.com/geekculture/introduction-to-neural-network-2f8b8221fbd3\n",
    "- Batches: https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
    "- Batch and Epoch: https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "- Batch Size: https://stackoverflow.com/questions/35050753/how-big-should-batch-size-and-number-of-epochs-be-when-fitting-a-model#:~:text=Generally%20batch%20size%20of%2032,have%20worked%20fine%20for%20me.\n",
    "- Activation Function: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "- Regularization: https://towardsdatascience.com/regularization-techniques-for-neural-networks-379f5b4c9ac3\n",
    "- Optimizer: https://medium.com/mlearning-ai/optimizers-in-deep-learning-7bf81fed78a0\n",
    "- Optimizer wählen: https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e\n",
    "- Best optimizer MNIST: https://towardsdatascience.com/neural-network-optimization-algorithms-1a44c282f61d#:~:text=We%20compared%20different%20optimizers%20used,on%20MNIST%20data%20in%20TensorFlow.\n",
    "- Boston Housing: https://www.kaggle.com/code/manishkc06/build-your-first-deep-learning-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540b3fc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
